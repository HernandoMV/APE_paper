{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# This notebook performs a statistical analysis on the learning rates between two groups of mice,\n",
    "# and generates publication-ready figures. It is split in 3 parts:\n",
    "\n",
    "# 1. Load requirements and basic exploration of the data\n",
    "# 2. Model fitting of individual mice, comparison of parameters\n",
    "#    and import of lesion data for each mouse from image analysis to remove individual mice from the study\n",
    "# 3. Statistical analysis between the groups to conclude differences and points of divergence in learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf APE_paper/\n",
    "!git clone https://github.com/HernandoMV/APE_paper.git\n",
    "%pip install git+file:///content/APE_paper\n",
    "%cd APE_paper/doc/figures_notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from APE_paper.utils import plot_utils\n",
    "from APE_paper.utils import custom_functions as cuf\n",
    "import os\n",
    "import sys\n",
    "from APE_paper.utils.misc_utils import update_progress\n",
    "import glob\n",
    "import ntpath\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "#from itertools import chains\n",
    "from scipy import stats\n",
    "import scipy.optimize as opt\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from datetime import date\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from itertools import chain\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset has been pre-processed, but conditions have not been selected\n",
    "# This preprocessing includes removal of disengaged trials\n",
    "# removal of the first 5 trials of each session\n",
    "# capped at 5000 trials\n",
    "\n",
    "# load the dataset\n",
    "dataset_path = '../datasets/Chronic-lesions_dataframe.csv'\n",
    "df_to_plot = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "# parameters for the plotting\n",
    "hue_order = ['Control', 'Lesion']\n",
    "color_palette = [(0.24715576, 0.49918708, 0.57655991), (160/255, 11/255 , 11/255)]\n",
    "sns.set_palette(color_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnimalID  ExperimentalGroup  Protocol\n",
       "CL-14     Lesion             Auditory    4936.0\n",
       "CL-15     Lesion             Auditory    4999.0\n",
       "CL-16     Lesion             Auditory    4968.0\n",
       "CL-17     Lesion             Auditory    4999.0\n",
       "CL-18     Lesion             Auditory    4922.0\n",
       "CL-19     Lesion             Auditory    4999.0\n",
       "CL-20     Lesion             Auditory    4534.0\n",
       "CL-21     Lesion             Auditory    4999.0\n",
       "CL-22     Lesion             Auditory    4999.0\n",
       "CL-23     Lesion             Auditory    4999.0\n",
       "CL-24     Lesion             Auditory    4999.0\n",
       "CL-25     Control            Auditory    4999.0\n",
       "CL-26     Control            Auditory    4452.0\n",
       "CL-27     Control            Auditory    4999.0\n",
       "CL-29     Control            Auditory    4999.0\n",
       "LFP16     Control            Auditory    4999.0\n",
       "LFP17     Control            Auditory    4999.0\n",
       "LFP18     Control            Auditory    4999.0\n",
       "LFP19     Control            Auditory    4999.0\n",
       "LFP20     Control            Auditory    4999.0\n",
       "LFP21     Control            Auditory    4959.0\n",
       "Name: CumulativeTrialNumberByProtocol, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maximum number of trials performed per mouse in the dataset:\n",
    "df_to_plot.groupby(['AnimalID', 'ExperimentalGroup', 'Protocol']).max()['CumulativeTrialNumberByProtocol']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance by session and 200-sized bins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin trials every 200\n",
    "df_to_plot[\"TrialIndexBinned200\"] = (df_to_plot.CumulativeTrialNumberByProtocol // 200) * 200 + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check on the data to see that it looks good\n",
    "ans_list = np.sort(df_to_plot.AnimalID.unique())\n",
    "num_ans = len(ans_list)\n",
    "fig, axs = plt.subplots(math.ceil(num_ans/3), 3,\n",
    "                        figsize=(15, num_ans),\n",
    "                        facecolor='w', edgecolor='k', sharey=True, sharex=True)\n",
    "fig.subplots_adjust(hspace = .2, wspace=.2)\n",
    "axs = axs.ravel()\n",
    "for i, ax in enumerate(axs):\n",
    "    if i < num_ans:\n",
    "        ax.hlines(50, 0, 5000, linestyles='dotted', alpha=0.4)\n",
    "    ax.axis('off')\n",
    "# process data from all animals\n",
    "for counter, animal in enumerate(ans_list):\n",
    "    ax = axs[counter]\n",
    "    \n",
    "    # plot here\n",
    "    sns.scatterplot(data=df_to_plot[df_to_plot.AnimalID == animal],\n",
    "                x=\"CumulativeTrialNumberByProtocol\",\n",
    "                y='CurrentPastPerformance100',\n",
    "                marker='.',\n",
    "                hue='SessionID',\n",
    "                alpha=.1,\n",
    "                ax=ax)\n",
    "    \n",
    "    # plot a line for binned trials\n",
    "    sns.lineplot(x=df_to_plot[df_to_plot.AnimalID == animal][\"TrialIndexBinned200\"] + 100, #trick to align as\n",
    "                 #CurrentPastPerformance looks at the past \n",
    "                 y=100 * df_to_plot[df_to_plot.AnimalID == animal][\"FirstPokeCorrect\"],\n",
    "                 color='k',\n",
    "                 ci=None,\n",
    "                 ax=ax)\n",
    "    \n",
    "    \n",
    "    ax.get_legend().remove()\n",
    "    ec = df_to_plot[df_to_plot.AnimalID == animal].ExperimentalGroup.unique()[0]\n",
    "    ax.text(.5,.95, ec + ': ' + animal, horizontalalignment='center', fontweight='bold', transform=ax.transAxes)\n",
    "\n",
    "    ax.axis('on')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    update_progress(counter / num_ans)\n",
    "    \n",
    "update_progress(1)\n",
    "# plt.savefig(data_directory + 'Performance_by_session_individual_animals.pdf', transparent=True, bbox_inches='tight')\n",
    "clear_output()\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colored dots show the performance of the past 100 trials using an average running window. Each color represents a distinct session. The black line shows the performance value of the past 200 trials using trial bining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit a sigmoid to every mouse to calculate and compare stages and learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the maximum performance for every mouse based on the trials binned every 200\n",
    "df_bin200tr = df_to_plot.groupby(['AnimalID','ExperimentalGroup','TrialIndexBinned200','Protocol']).median().reset_index()\n",
    "mouse_max_perf = df_bin200tr.groupby('AnimalID').max().reset_index()[['AnimalID', 'CurrentPastPerformance100']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the models for the fitting\n",
    "# sigmoid function\n",
    "def sigmoid_func(x, perf_end, slope, bias): \n",
    "    return (perf_end - 0.5) / (1 + np.exp(-slope * (x - bias))) + 0.5\n",
    "\n",
    "# sigmoid function scaled\n",
    "def sigmoid_func_sc(x, perf_end, slope, bias): \n",
    "    return (perf_end - 50) / (1 + np.exp(-slope * (x - bias))) + 50\n",
    "\n",
    "# derivative function\n",
    "def der_sig(x, perf_end, slope, bias):\n",
    "    return (perf_end - 50) * slope * np.exp(- slope * (x - bias)) / (1 + np.exp(- slope * (x - bias)))**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid function is (perf_end - 0.5) / (1 + np.exp(-slope * (x - bias))) + 0.5\n",
    "\n",
    "Data is scaled before the fitting and parameters are rescaled afterwards\n",
    "\n",
    "The maximum performace possible is defined as the maximum of the median of the trials binned every 200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_list = np.sort(df_to_plot.AnimalID.unique())\n",
    "num_ans = len(ans_list)\n",
    "# create a diccionary to store the results, and lists to rescale the data\n",
    "fit_dir = {}\n",
    "xmeans_list = []\n",
    "xsd_list = []\n",
    "\n",
    "# process data from all animals\n",
    "for counter, animal in enumerate(ans_list):\n",
    "    df = df_to_plot[df_to_plot.AnimalID==animal][\n",
    "        ['CumulativeTrialNumberByProtocol',\n",
    "         'CurrentPastPerformance100',\n",
    "         'SessionID']\n",
    "    ].dropna()\n",
    "    \n",
    "    # calculate and plot the fitting\n",
    "    xdata = np.array(df.CumulativeTrialNumberByProtocol)\n",
    "    ydata = np.array(df.CurrentPastPerformance100)\n",
    "    \n",
    "    # scale the data\n",
    "    xdatasc = (xdata - xdata.mean()) / xdata.std()\n",
    "    ydatasc = ydata / 100\n",
    "    \n",
    "    # limit to the maximum performance for this mouse:\n",
    "    mp = mouse_max_perf[mouse_max_perf.AnimalID==animal].CurrentPastPerformance100.iloc[0] / 100\n",
    "\n",
    "    cost_func = lambda x: np.mean(np.abs(sigmoid_func(xdatasc, x[0], x[1], x[2]) - ydatasc))\n",
    "    res = opt.minimize(cost_func, [1, 0, 0], bounds=((0.5, mp), (0., 10.), (None,None)))\n",
    "\n",
    "    update_progress(counter / num_ans)\n",
    "    \n",
    "    #update dicctionary and lists\n",
    "    fit_dir[animal] = res\n",
    "    xmeans_list.append(xdata.mean())\n",
    "    xsd_list.append(xdata.std())\n",
    "    \n",
    "update_progress(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataframe\n",
    "fit_df = pd.DataFrame({\n",
    "    'AnimalID': list(fit_dir.keys()),\n",
    "    'maximum_performance': [v.x[0] for k, v in fit_dir.items()],\n",
    "    'slope': [v.x[1] for k, v in fit_dir.items()],\n",
    "    'bias': [v.x[2] for k, v in fit_dir.items()]\n",
    "})\n",
    "# get the Experimental procedure\n",
    "fit_df['ExperimentalGroup'] = fit_df['AnimalID'].apply(\n",
    "        lambda x: df_to_plot[df_to_plot.AnimalID==x].ExperimentalGroup.unique()[0]\n",
    "    )\n",
    "# rescale back the coefficients\n",
    "fit_df.maximum_performance = fit_df.maximum_performance * 100\n",
    "fit_df.slope = fit_df.slope / np.array(xsd_list)\n",
    "fit_df.bias = fit_df.bias * np.array(xsd_list) + np.array(xmeans_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find the steepest point of each slope (max of derivative)\n",
    "der_max_dir = {}\n",
    "for animal in ans_list:\n",
    "    m_point = opt.fmin(lambda x: -der_sig(x, *[fit_df[fit_df.AnimalID==animal].maximum_performance.iloc[0],\n",
    "                                               fit_df[fit_df.AnimalID==animal].slope.iloc[0],\n",
    "                                               fit_df[fit_df.AnimalID==animal].bias.iloc[0]]), 0, full_output=True)\n",
    "    \n",
    "    der_max_dir[animal] = (m_point[0][0], -m_point[1])\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the curves again pointing to the maximum\n",
    "# sanity check to see that these scaled values recreate the curves\n",
    "\n",
    "x = np.linspace(1,5000)\n",
    "\n",
    "fig, axs = plt.subplots(math.ceil(num_ans/3), 3,\n",
    "                        figsize=(15, num_ans),\n",
    "                        facecolor='w', edgecolor='k', sharey=True, sharex=True)\n",
    "fig.subplots_adjust(hspace = .2, wspace=.2)\n",
    "axs = axs.ravel()\n",
    "for i, ax in enumerate(axs):\n",
    "    if i < num_ans:\n",
    "        ax.hlines(50, 0, 5000, linestyles='dotted', alpha=0.4)\n",
    "    ax.axis('off')\n",
    "# process data from all animals\n",
    "for counter, animal in enumerate(ans_list):\n",
    "    ax = axs[counter]\n",
    "    df = df_to_plot[df_to_plot.AnimalID==animal][\n",
    "        ['CumulativeTrialNumberByProtocol',\n",
    "         'CurrentPastPerformance100',\n",
    "         'SessionID']\n",
    "    ].dropna()\n",
    "    \n",
    "    # plot here\n",
    "    sns.scatterplot(data=df,\n",
    "                x=\"CumulativeTrialNumberByProtocol\",\n",
    "                y='CurrentPastPerformance100',\n",
    "                marker='.',\n",
    "                hue='SessionID',\n",
    "                alpha=.1,\n",
    "                ax=ax)\n",
    "    \n",
    "    sns.lineplot(x=x,\n",
    "                 y=sigmoid_func_sc(x, *[fit_df[fit_df.AnimalID==animal].maximum_performance.iloc[0],\n",
    "                                        fit_df[fit_df.AnimalID==animal].slope.iloc[0],\n",
    "                                        fit_df[fit_df.AnimalID==animal].bias.iloc[0]]),\n",
    "                 color='k',\n",
    "                 ci=None,\n",
    "                 ax=ax)\n",
    "    \n",
    "    ax.get_legend().remove()\n",
    "    ec = df_to_plot[df_to_plot.AnimalID == animal].ExperimentalGroup.unique()[0]\n",
    "    ax.text(.5,.9, ec + ': ' + animal, horizontalalignment='center', fontweight='bold', transform=ax.transAxes)\n",
    "\n",
    "    ax.axis('on')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    update_progress(counter / num_ans)\n",
    "\n",
    "\n",
    "# point to the maximum slope\n",
    "ymin, ymax = plt.gca().get_ybound()\n",
    "for counter, animal in enumerate(ans_list):\n",
    "    ax = axs[counter] \n",
    "    perc_max_slope = sigmoid_func_sc(der_max_dir[animal][0],\n",
    "                                     *[fit_df[fit_df.AnimalID==animal].maximum_performance.iloc[0],\n",
    "                                       fit_df[fit_df.AnimalID==animal].slope.iloc[0],\n",
    "                                       fit_df[fit_df.AnimalID==animal].bias.iloc[0]])\n",
    "    ax.axvline(fit_df[fit_df.AnimalID==animal].bias.iloc[0], 0, (perc_max_slope - ymin) / (ymax - ymin), linestyle='--', color='k')\n",
    "    ax.plot([0, fit_df[fit_df.AnimalID==animal].bias.iloc[0]], [perc_max_slope,perc_max_slope], 'k--')\n",
    "    \n",
    "update_progress(1)\n",
    "# plt.savefig(data_directory + 'Sigmoid_fitting.pdf', transparent=True, bbox_inches='tight')\n",
    "clear_output()\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a learning speed measure I use the point of the maximum learning rate, which is the maximum of the derivative of the fitting, which is also the middle point of the curve (in between 50% and maximum performance)\n",
    "The bias indicates where this point lies in the x axis: at which trial number this point is reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the maximum value of the derivative to the fit_df dataframe\n",
    "for key, value in der_max_dir.items():\n",
    "    fit_df.loc[fit_df.index[fit_df['AnimalID'] == key].tolist()[0], 'max_of_der'] = value[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences of parameters between groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate significance\n",
    "parameters_to_show = ['maximum_performance', 'max_of_der', 'bias']\n",
    "# define three levels of significance for the plotting\n",
    "sig_levels = [0.05, 0.01, 0.001]\n",
    "pvals = []\n",
    "print('Kluskal-Wallis tests on the parameters')\n",
    "for var in parameters_to_show:\n",
    "    kt = stats.kruskal(fit_df[fit_df.ExperimentalGroup==hue_order[0]][var].dropna(),\n",
    "                       fit_df[fit_df.ExperimentalGroup==hue_order[1]][var].dropna())\n",
    "    print( var + ':\\t\\tpvalue: ' + str(kt.pvalue) )\n",
    "    pvals.append(kt.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the parameters between groups\n",
    "titles = ['maximum\\nperformance', 'maximum\\nlearning rate', 'trials to mid\\nperformance']\n",
    "ylabs = ['task performance (%)', '\\u0394performance \\u00D7 trials$\\mathregular{^{-1}}$',\\\n",
    "         'number of trials']\n",
    "spread=.3\n",
    "\n",
    "fig, axs = plt.subplots(ncols=3, nrows=1, sharey=False, figsize=(10,4))\n",
    "axs = axs.ravel()\n",
    "for i, var in enumerate(parameters_to_show):\n",
    "    \n",
    "    sns.swarmplot(data=fit_df,\n",
    "                  x='ExperimentalGroup',\n",
    "                  y=var,\n",
    "                  order=hue_order,\n",
    "                  hue='ExperimentalGroup',\n",
    "                  hue_order=hue_order,\n",
    "                  dodge=False, #jitter=.25,\n",
    "                  alpha=.5, zorder=1, size=8,\n",
    "                  ax=axs[i])\n",
    "    \n",
    "    # boxplot next to it\n",
    "    for k, egr in enumerate(hue_order):\n",
    "        bpdat = fit_df[fit_df.ExperimentalGroup == egr][var].values\n",
    "        bp = axs[i].boxplot([bpdat], positions=[k+spread], widths=0.1, \n",
    "                            patch_artist=True, showfliers=False)\n",
    "        for element in ['boxes', 'whiskers', 'fliers', 'means', 'medians', 'caps']:\n",
    "            plt.setp(bp[element], color=color_palette[k], linewidth=2)\n",
    "        for patch in bp['boxes']:\n",
    "            patch.set(facecolor='white')\n",
    "    \n",
    "    \n",
    "    axs[i].set_title(titles[i])\n",
    "    axs[i].set_ylabel(ylabs[i])\n",
    "    \n",
    "for ax in axs:\n",
    "    \n",
    "    # Hide the right and top spines\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    # Only show ticks on the left\n",
    "    #ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks([])\n",
    "    ax.xaxis.set_visible(False)\n",
    "\n",
    "# fix individual axis\n",
    "axs[0].set_ylim(65, 100)\n",
    "axs[1].set_ylim(-0.00, axs[1].get_ylim()[1])\n",
    "axs[2].set_ylim(0, axs[2].get_ylim()[1])\n",
    "\n",
    "axs[1].get_legend().remove()\n",
    "axs[2].get_legend().remove()\n",
    "axs[0].get_legend().remove()\n",
    "\n",
    "# add statistics\n",
    "# for lesions\n",
    "yvals = [70, 0.001, 300]\n",
    "\n",
    "for i,ax in enumerate(axs):\n",
    "    n_ast = sum(pvals[i] < sig_levels)\n",
    "    plot_utils.add_stats(ax, xvals=(spread/2, 1+spread/2), yval=yvals[i], n_asterisks=n_ast)    \n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(data_directory + 'Parameters_group_comparison.pdf', transparent=True, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,s in enumerate(sig_levels):\n",
    "    print(i+1, 'asterisks: pval <', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess difference in movement parameters\n",
    "\n",
    "# CLEAN THIS TO WHAT WE DO SHOW!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate ITIs\n",
    "\n",
    "itis_list = []\n",
    "for Sid in pd.unique(df_to_plot.SessionID):\n",
    "    itis = cuf.itis_calculator(df_to_plot[df_to_plot.SessionID==Sid])\n",
    "    itis_list.append(itis)\n",
    "#     df_to_plot[df_to_plot.SessionID==Sid, 'ITI'] = itis\n",
    "#     print(df_to_plot[df_to_plot.SessionID==Sid].shape)\n",
    "#     print(len(itis))\n",
    "# TrialStartTimestamp\n",
    "df_to_plot['ITI'] = np.array(list(chain(*[x for x in itis_list])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare values in between animals at a comparable performance level\n",
    "df_by_an = df_to_plot[np.logical_and(df_to_plot.CumulativePerformance > 70, df_to_plot.CumulativePerformance < 80)].groupby(['AnimalID','ExperimentalGroup']).median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate significance\n",
    "columns_to_plot = ['NoOfCenterPokes', 'TrialInitiationTime',\\\n",
    "                   'MiddleWaitTime', 'ITI']\n",
    "# define three levels of significance for the plotting\n",
    "sig_levels = [0.05, 0.01, 0.001]\n",
    "pvals = []\n",
    "print('Kluskal-Wallis tests on the parameters')\n",
    "for var in columns_to_plot:\n",
    "    kt = stats.kruskal(df_by_an[df_by_an.ExperimentalGroup==hue_order[0]][var].dropna(),\n",
    "                       df_by_an[df_by_an.ExperimentalGroup==hue_order[1]][var].dropna())\n",
    "    print(var + ':\\t\\tpvalue: ' + str(kt.pvalue) )\n",
    "    pvals.append(kt.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the parameters between groups\n",
    "spread=.3\n",
    "\n",
    "fig, axs = plt.subplots(ncols=4, nrows=1, sharey=False, figsize=(10,4))\n",
    "axs = axs.ravel()\n",
    "for i, var in enumerate(columns_to_plot):\n",
    "    \n",
    "    sns.swarmplot(data=df_by_an,\n",
    "                  x='ExperimentalGroup',\n",
    "                  y=var,\n",
    "                  order=hue_order,\n",
    "                  hue='ExperimentalGroup',\n",
    "                  hue_order=hue_order,\n",
    "                  dodge=False, #jitter=.25,\n",
    "                  alpha=.5, zorder=1, size=8,\n",
    "                  ax=axs[i])\n",
    "    \n",
    "    # boxplot next to it\n",
    "    for k, egr in enumerate(hue_order):\n",
    "        bpdat = df_by_an[df_by_an.ExperimentalGroup == egr][var].values\n",
    "        bp = axs[i].boxplot([bpdat], positions=[k+spread], widths=0.1, \n",
    "                            patch_artist=True, showfliers=False)\n",
    "        for element in ['boxes', 'whiskers', 'fliers', 'means', 'medians', 'caps']:\n",
    "            plt.setp(bp[element], color=color_palette[k], linewidth=2)\n",
    "        for patch in bp['boxes']:\n",
    "            patch.set(facecolor='white')\n",
    "    \n",
    "for ax in axs:    \n",
    "    # Hide the right and top spines\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    # Only show ticks on the left\n",
    "    #ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks([])\n",
    "    ax.xaxis.set_visible(False)\n",
    "\n",
    "\n",
    "# axs[2].set_ylim(0, axs[2].get_ylim()[1])\n",
    "# axs[3].set_ylim(0, axs[3].get_ylim()[1])\n",
    "\n",
    "\n",
    "axs[1].get_legend().remove()\n",
    "axs[2].get_legend().remove()\n",
    "axs[0].get_legend().remove()\n",
    "axs[3].get_legend().remove()\n",
    "\n",
    "# add statistics\n",
    "# for 6OHDA\n",
    "# yvals = [75, 0.003, 500, 0.01]\n",
    "# for D1 pre\n",
    "# yvals = [40, -0.005, 500]\n",
    "# for lesions\n",
    "# yvals = [65, 0.001, 300, 0.01]\n",
    "\n",
    "# for i,ax in enumerate(axs):\n",
    "#     n_ast = sum(pvals[i] < sig_levels)\n",
    "#     plot_utils.add_stats(ax, xvals=(spread/2, 1+spread/2), yval=yvals[i], n_asterisks=n_ast)    \n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(data_directory + 'Motor_Parameters_group_comparison_median.pdf', transparent=True, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate the statistical differences of performances between groups at different points in learning time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do not consider trials in which the animal is too biased to calculate performance, as the antibias acts making the mice be worse than chance and that can obscure effects of learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_top_threshold = np.nanmean(df_to_plot.RightBias) + 2 * np.nanstd(df_to_plot.RightBias)\n",
    "bias_bottom_threshold = np.nanmean(df_to_plot.RightBias) - 2 * np.nanstd(df_to_plot.RightBias)\n",
    "\n",
    "bias_mask = np.logical_and(df_to_plot.RightBias < bias_top_threshold, df_to_plot.RightBias > bias_bottom_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sanity check on the data to see that it looks good\n",
    "ans_list = np.sort(df_to_plot.AnimalID.unique())\n",
    "num_ans = len(ans_list)\n",
    "fig, axs = plt.subplots(math.ceil(num_ans/3), 3,\n",
    "                        figsize=(15, num_ans),\n",
    "                        facecolor='w', edgecolor='k', sharey=True, sharex=True)\n",
    "fig.subplots_adjust(hspace = .2, wspace=.2)\n",
    "axs = axs.ravel()\n",
    "for i, ax in enumerate(axs):\n",
    "    if i < num_ans:\n",
    "        ax.hlines(50, 0, 5000, linestyles='dotted', alpha=0.4)\n",
    "    ax.axis('off')\n",
    "# process data from all animals\n",
    "for counter, animal in enumerate(ans_list):\n",
    "    ax = axs[counter]\n",
    "    \n",
    "    # plot here\n",
    "    sns.scatterplot(data=df_to_plot[df_to_plot.AnimalID == animal],\n",
    "                x=\"CumulativeTrialNumberByProtocol\",\n",
    "                y='CurrentPastPerformance100',\n",
    "                marker='.',\n",
    "                color='red',\n",
    "                alpha=.1,\n",
    "                ax=ax)\n",
    "    \n",
    "    sns.scatterplot(data=df_to_plot[np.logical_and(df_to_plot.AnimalID == animal, bias_mask)],\n",
    "                x=\"CumulativeTrialNumberByProtocol\",\n",
    "                y='CurrentPastPerformance100',\n",
    "                marker='.',\n",
    "                color='green',\n",
    "                alpha=.1,\n",
    "                ax=ax)\n",
    "    \n",
    "    \n",
    "#     ax.get_legend().remove()\n",
    "    ec = df_to_plot[df_to_plot.AnimalID == animal].ExperimentalGroup.unique()[0]\n",
    "    ax.text(.5,.95, ec + ': ' + animal, horizontalalignment='center', fontweight='bold', transform=ax.transAxes)\n",
    "\n",
    "    ax.axis('on')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    update_progress(counter / num_ans)\n",
    "    \n",
    "update_progress(1)\n",
    "# plt.savefig(data_directory + 'Performance_by_session_individual_animals_bias-removal.pdf', transparent=True, bbox_inches='tight')\n",
    "clear_output()\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recalculate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAST_WINDOW = 100\n",
    "CumPerList = []\n",
    "for Sid in pd.unique(df_to_plot['SessionID']):\n",
    "    CumPerList.append(cuf.perf_window_calculator(df_to_plot[np.logical_and(bias_mask,\n",
    "                                                                           df_to_plot['SessionID']==Sid)],\n",
    "                                                 PAST_WINDOW))\n",
    "# flatten the list of lists\n",
    "df_to_plot.loc[bias_mask, 'CurrentPastPerformance100biasremoved'] = np.array(list(chain(*[x for x in CumPerList])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure1X\n",
    "col_to_plot = 'CurrentPastPerformance100biasremoved'\n",
    "data_mean = df_to_plot.groupby(['CumulativeTrialNumberByProtocol','ExperimentalGroup'])[col_to_plot].mean().reset_index()\n",
    "st_err_mean = df_to_plot.groupby(['CumulativeTrialNumberByProtocol','ExperimentalGroup'])[col_to_plot].std().reset_index()\n",
    "data_mean['low_bound'] = data_mean[col_to_plot] - st_err_mean[col_to_plot]\n",
    "data_mean['high_bound'] = data_mean[col_to_plot] + st_err_mean[col_to_plot]\n",
    "\n",
    "fig1 = plt.figure(figsize=(8, 4))\n",
    "plt.axhline(50, ls='dotted', alpha=0.4, color='k')\n",
    "plt.axhline(100, ls='dotted', alpha=0.4, color='k')\n",
    "for i,eg in enumerate(hue_order):\n",
    "    df = data_mean[data_mean.ExperimentalGroup==eg].copy()\n",
    "    x = df.CumulativeTrialNumberByProtocol\n",
    "    plt.plot(x, df[col_to_plot], color=color_palette[i], label=eg)\n",
    "    y1 = df['low_bound']\n",
    "    y2 = df['high_bound']\n",
    "    plt.fill_between(x, y1, y2, where=y2 >= y1, color=color_palette[i], alpha=.2, interpolate=False)\n",
    "\n",
    "plt.ylabel(col_to_plot)\n",
    "plt.xlabel('trial number')\n",
    "plt.ylabel('task performance (%)')\n",
    "plt.legend(loc=(0.76,0.3), frameon=False)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# remove the legend as the figure has it's own\n",
    "ax.get_legend().remove()\n",
    "\n",
    "ax.set_xlim((0,5000))\n",
    "\n",
    "plt.title('Task learning progression')\n",
    "\n",
    "# plt.savefig(data_directory + 'Performance_between_groups.pdf', transparent=True, bbox_inches='tight')\n",
    "fig1.show()\n",
    "print('Shaded area indicates std, and performance is calculated using', col_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a 100-trial window to bin the data\n",
    "xbin = 100\n",
    "df_to_plot[\"TrialIndexBinned\"] = (df_to_plot.CumulativeTrialNumberByProtocol // xbin) * xbin + xbin / 2\n",
    "print('Trials are binned in groups of', xbin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby so each animal has a mean of the performance in each bin\n",
    "df_bintr = df_to_plot.groupby(['AnimalID','ExperimentalGroup','TrialIndexBinned','Protocol']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a scaled version of the performance\n",
    "df_bintr['Performance'] = df_bintr.FirstPokeCorrect * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the differences of the means using the binned data\n",
    "perdif_df = df_bintr[df_bintr.ExperimentalGroup == hue_order[0]].groupby('TrialIndexBinned').mean()['Performance'] -\\\n",
    "            df_bintr[df_bintr.ExperimentalGroup == hue_order[1]].groupby('TrialIndexBinned').mean()['Performance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now can measure the differences between the means of the two groups\n",
    "\n",
    "#### Calculate the significance by resampling: suffle the group labels multiple times and calculate the likelihood of observing this data\n",
    "References:\n",
    "\n",
    "Supplementary figure 4 in here: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2562676/\n",
    "\n",
    "See also methods here: https://www.biorxiv.org/content/10.1101/716274v3.full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to generate a list of experimental groups randomly\n",
    "def generate_eg(list_size, prob, labs = hue_order):\n",
    "    ltr = []\n",
    "    for i in range(list_size):\n",
    "        if random.random() < prob:\n",
    "            ltr.append(labs[0])\n",
    "        else:\n",
    "            ltr.append(labs[1])\n",
    "    return ltr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the important columns\n",
    "df_colsel = df_bintr[['AnimalID', 'ExperimentalGroup', 'TrialIndexBinned', 'Performance']].copy()\n",
    "# get the experimental group for each animal\n",
    "exp_gr = [df_colsel[df_colsel.AnimalID==x].ExperimentalGroup.unique()[0] for x in df_colsel.AnimalID.unique()]\n",
    "# get the number of mice\n",
    "n_an = len(exp_gr)\n",
    "# get the probability of a mouse to be a control for this dataset\n",
    "cb_prob = sum([x==hue_order[0] for x in exp_gr]) / n_an\n",
    "# set random seed\n",
    "np.random.seed(124321)\n",
    "# calculate the differences of means by resampling\n",
    "shuff_res = []\n",
    "nsh = 10000\n",
    "for i in range(nsh):\n",
    "    # shuffle the list of groups by assigning a probability for each mouse to be in a group based on the real ratio\n",
    "    exp_grs = generate_eg(n_an, cb_prob)\n",
    "    # create a diccionary\n",
    "    egs_dict = dict(zip(df_colsel.AnimalID.unique(), exp_grs))\n",
    "    # create a new column with the shuffled group\n",
    "    df_colsel['egs'] = [egs_dict[x] for x in df_colsel.AnimalID]\n",
    "    # calculate the differences and append\n",
    "    shuff_res.append(df_colsel[df_colsel.egs == hue_order[0]].groupby('TrialIndexBinned').mean()['Performance'] -\\\n",
    "                     df_colsel[df_colsel.egs == hue_order[1]].groupby('TrialIndexBinned').mean()['Performance'])\n",
    "    update_progress(i / nsh)\n",
    "# save in a data frame format\n",
    "shrdf = pd.concat(shuff_res)\n",
    "update_progress(1)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = df_colsel[df_colsel.ExperimentalGroup == hue_order[0]].groupby('TrialIndexBinned').mean()['Performance'] -\\\n",
    "            df_colsel[df_colsel.ExperimentalGroup == hue_order[1]].groupby('TrialIndexBinned').mean()['Performance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shuffling respects the proportion of mice in every group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data is shuffled', nsh, 'times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "pos_ci = shrdf.groupby('TrialIndexBinned').quantile(.95)\n",
    "neg_ci = shrdf.groupby('TrialIndexBinned').quantile(.05)\n",
    "\n",
    "fig2 = plt.figure(figsize=(8, 4))\n",
    "plt.axhline(0, ls='dotted', alpha=0.4, color='k')\n",
    "plt.plot(real_data, color='k', label='observed data')\n",
    "plt.plot(pos_ci, linestyle='--', color='gray', label='95% ci')\n",
    "plt.plot(neg_ci, linestyle='--', color='gray')\n",
    "x = pos_ci.reset_index().TrialIndexBinned\n",
    "y1 = pos_ci.reset_index().Performance\n",
    "y2 = real_data.reset_index().Performance\n",
    "plt.fill_between(x, y1, y2, where=y2 >= y1, facecolor='k', alpha=.2, interpolate=True)\n",
    "plt.ylabel('performance difference (%)')\n",
    "plt.xlabel('trial number')\n",
    "plt.legend(loc=(0.75,0.05), frameon=False)\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.set_xlim((0,5000))\n",
    "\n",
    "# plt.savefig(data_directory + 'Differences_of_means_significance_by_trial_bins.pdf',transparent=True, bbox_inches='tight')\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The red line shows the difference between the means in terms of performance.\n",
    "The dotted lines show 95% confidence intervals for shuffled data.\n",
    "\n",
    "This shows how likely is that each point crosses the line (point-base significance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Substitute of the mixed anova: find the likelihood of any point being significant. Shuffle more data and quantify the percentage of times there is a crossing. Generate global bands of confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quants_to_test = [0.99, 0.995, 0.996, 0.997, 0.998, 0.999, 0.9999]\n",
    "nsh=1000\n",
    "# create an empty array to store results\n",
    "global_sig = np.empty((nsh, len(quants_to_test)), dtype=bool)\n",
    "# loop over shuffle data\n",
    "for i in range(nsh):\n",
    "    # shuffle the list of groups by assigning a probability for each mouse to be in a group based on the real ratio\n",
    "    exp_grs = generate_eg(n_an, cb_prob)\n",
    "    # create a diccionary\n",
    "    egs_dict = dict(zip(df_colsel.AnimalID.unique(), exp_grs))\n",
    "    # create a new column with the shuffled group\n",
    "    df_colsel['egs'] = [egs_dict[x] for x in df_colsel.AnimalID]\n",
    "    # calculate the differences\n",
    "    sh_dif = df_colsel[df_colsel.egs == hue_order[0]].groupby('TrialIndexBinned').mean()['Performance'] -\\\n",
    "                     df_colsel[df_colsel.egs == hue_order[1]].groupby('TrialIndexBinned').mean()['Performance']\n",
    "    # for each quantile band, what percentages of lines cross at any point\n",
    "    for k,q in enumerate(quants_to_test):\n",
    "        global_sig[i,k] = any(np.logical_or(sh_dif > shrdf.groupby('TrialIndexBinned').quantile(q),\n",
    "                                            sh_dif < shrdf.groupby('TrialIndexBinned').quantile(1 - q)))\n",
    "        \n",
    "    update_progress(i / nsh)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('New shuffled data,', nsh, 'times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confidence intervals and print their global p-values:\n",
    "plt.figure(figsize=(16, 4))\n",
    "sns.lineplot(data=real_data, color='r')\n",
    "for k,q in enumerate(quants_to_test):\n",
    "    sns.lineplot(data=shrdf.groupby('TrialIndexBinned').quantile(q), color='k')\n",
    "    sns.lineplot(data=shrdf.groupby('TrialIndexBinned').quantile((1 - q)), color='k')\n",
    "    print('ci = ', q,\n",
    "          '\\tglobal pval = ',  np.sum(global_sig, axis=0)[k] / nsh,\n",
    "          '\\treal data significant ', any(np.logical_or(real_data > shrdf.groupby('TrialIndexBinned').quantile(q),\n",
    "                                            real_data < shrdf.groupby('TrialIndexBinned').quantile(1 - q))))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('APE_paper')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2ee272fe26eecc87357a56bca0cf8dd5255900133eec92d0d83e2a7e1aaf1681"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
